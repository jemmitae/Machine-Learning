{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9\n",
    "\n",
    "## Mashable news stories analysis\n",
    "\n",
    "Predicting if a news story is going to be popular\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>Popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>http://mashable.com/2014/12/10/cia-torture-rep...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.732620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.487500</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>http://mashable.com/2013/10/18/bitlock-kicksta...</td>\n",
       "      <td>447.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.653199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.135340</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>http://mashable.com/2013/07/24/google-glass-po...</td>\n",
       "      <td>533.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>http://mashable.com/2013/11/21/these-are-the-m...</td>\n",
       "      <td>413.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.497409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.677350</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.195701</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>http://mashable.com/2014/02/11/parking-ticket-...</td>\n",
       "      <td>331.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                url  timedelta  \\\n",
       "0           0  http://mashable.com/2014/12/10/cia-torture-rep...       28.0   \n",
       "1           1  http://mashable.com/2013/10/18/bitlock-kicksta...      447.0   \n",
       "2           2  http://mashable.com/2013/07/24/google-glass-po...      533.0   \n",
       "3           3  http://mashable.com/2013/11/21/these-are-the-m...      413.0   \n",
       "4           4  http://mashable.com/2014/02/11/parking-ticket-...      331.0   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0             9.0             188.0         0.732620               1.0   \n",
       "1             7.0             297.0         0.653199               1.0   \n",
       "2            11.0             181.0         0.660377               1.0   \n",
       "3            12.0             781.0         0.497409               1.0   \n",
       "4             8.0             177.0         0.685714               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs   ...     \\\n",
       "0                  0.844262        5.0             1.0   ...      \n",
       "1                  0.815789        9.0             4.0   ...      \n",
       "2                  0.775701        4.0             3.0   ...      \n",
       "3                  0.677350       10.0             3.0   ...      \n",
       "4                  0.830357        3.0             2.0   ...      \n",
       "\n",
       "   min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0               0.200000                   0.80              -0.487500   \n",
       "1               0.160000                   0.50              -0.135340   \n",
       "2               0.136364                   1.00               0.000000   \n",
       "3               0.100000                   1.00              -0.195701   \n",
       "4               0.100000                   0.55              -0.175000   \n",
       "\n",
       "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                  -0.60              -0.250000                 0.9   \n",
       "1                  -0.40              -0.050000                 0.1   \n",
       "2                   0.00               0.000000                 0.3   \n",
       "3                  -0.40              -0.071429                 0.0   \n",
       "4                  -0.25              -0.100000                 0.0   \n",
       "\n",
       "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                       0.8                     0.4   \n",
       "1                      -0.1                     0.4   \n",
       "2                       1.0                     0.2   \n",
       "3                       0.0                     0.5   \n",
       "4                       0.0                     0.5   \n",
       "\n",
       "   abs_title_sentiment_polarity  Popular  \n",
       "0                           0.8        1  \n",
       "1                           0.1        0  \n",
       "2                           1.0        0  \n",
       "3                           0.0        0  \n",
       "4                           0.0        0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/albahnsen/PracticalMachineLearningClass/master/datasets/mashable.csv'\n",
    "train_df = pd.read_csv(url)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 62)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(['url', 'Popular'], axis=1)\n",
    "y = train_df['Popular']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#publicar o no publicar\n",
    "#medir el potencial impacto\n",
    "#cuanto cobro a los que ponen publicidad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.1\n",
    "\n",
    "Estimate a Decision Tree Classifier and a Logistic Regresion\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "models = {'lo': LogisticRegression(),\n",
    "          'dt': DecisionTreeClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for model in models.keys():\n",
    "    models[model].fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(index=y_test.index, columns=models.keys())\n",
    "for model in models.keys():\n",
    "    y_pred[model] = models[model].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lo</th>\n",
       "      <th>dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5224</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3593</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5351</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5470</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3707</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5112</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5756</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3754</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3628</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4829</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5829</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5274</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5010</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4048</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3307</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3080</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5136</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5826</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5887</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4483</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1980 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lo  dt\n",
       "1782   0   0\n",
       "3917   1   0\n",
       "221    0   1\n",
       "2135   0   0\n",
       "5224   0   0\n",
       "1168   0   0\n",
       "879    0   0\n",
       "156    0   1\n",
       "1657   1   1\n",
       "323    0   0\n",
       "5302   1   0\n",
       "2611   0   0\n",
       "811    0   1\n",
       "393    1   0\n",
       "3593   0   1\n",
       "2638   1   1\n",
       "2187   1   0\n",
       "5351   0   0\n",
       "319    0   0\n",
       "167    1   0\n",
       "746    1   0\n",
       "5470   1   1\n",
       "3707   0   0\n",
       "2764   1   1\n",
       "5112   0   1\n",
       "4006   1   1\n",
       "1871   0   0\n",
       "5756   1   1\n",
       "3193   0   0\n",
       "3754   0   1\n",
       "...   ..  ..\n",
       "3628   0   1\n",
       "4829   0   0\n",
       "2149   0   0\n",
       "139    0   1\n",
       "5829   1   1\n",
       "5274   1   0\n",
       "2284   0   1\n",
       "5010   1   1\n",
       "1149   1   1\n",
       "4048   0   1\n",
       "2498   0   0\n",
       "2273   1   0\n",
       "2526   1   1\n",
       "463    0   0\n",
       "3307   0   0\n",
       "3132   1   0\n",
       "4985   0   0\n",
       "594    1   1\n",
       "3080   0   1\n",
       "1807   1   1\n",
       "5136   0   1\n",
       "450    1   1\n",
       "3043   0   0\n",
       "5826   0   0\n",
       "518    0   1\n",
       "2522   0   1\n",
       "312    0   1\n",
       "5887   0   1\n",
       "4483   1   1\n",
       "2647   0   0\n",
       "\n",
       "[1980 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lo 0.6034413096079967\n",
      "dt 0.6493975452041467\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for model in models.keys():\n",
    "    print(model,np.sqrt(mean_squared_error(y_pred[model], y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5456439065244592"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_pred.mean(axis=1), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lo 0.6183165696135521\n",
      "dt 0.5754956786985257\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "for model in models.keys():\n",
    "    print(model, metrics.f1_score(y_pred[model], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.2\n",
    "\n",
    "Estimate 300 bagged samples\n",
    "\n",
    "Estimate the following set of classifiers:\n",
    "\n",
    "* 100 Decision Trees where max_depth=None -- 100 arboles\n",
    "* 100 Decision Trees where max_depth=2 -- 100 arboles\n",
    "* 100 Logistic Regressions -- reg log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "bagreg = BaggingRegressor(DecisionTreeClassifier(max_depth=None), n_estimators=100, \n",
    "                          bootstrap=True, oob_score=True, random_state=1)\n",
    "bagreg1 = BaggingRegressor(DecisionTreeClassifier(max_depth=2), n_estimators=100, \n",
    "                          bootstrap=True, oob_score=True, random_state=1)\n",
    "bagreg2 = BaggingRegressor(LogisticRegression(penalty='l1', solver='liblinear'), n_estimators=100, \n",
    "                          bootstrap=True, oob_score=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.  , 1.  , 0.96, ..., 0.82, 1.  , 1.  ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagreg.fit(X_train, y_train)\n",
    "y_pred = bagreg.predict(X_test)\n",
    "y_pred\n",
    "\n",
    "bagreg1.fit(X_train, y_train)\n",
    "y_pred1 = bagreg1.predict(X_test)\n",
    "y_pred1\n",
    "\n",
    "bagreg2.fit(X_train, y_train)\n",
    "y_pred2 = bagreg2.predict(X_test)\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.3\n",
    "\n",
    "Ensemble using majority voting\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 100\n",
    "# set a seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "\n",
    "# create bootstrap samples (will be used to select rows from the DataFrame)\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(n_estimators)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "np.random.seed(123) \n",
    "seeds = np.random.randint(1, 10000, size=n_estimators)\n",
    "\n",
    "trees = {}\n",
    "for i in range(n_estimators):\n",
    "    trees[i] = DecisionTreeClassifier(max_features=\"sqrt\", max_depth=None, random_state=seeds[i])\n",
    "    trees[i].fit(X_train.iloc[samples[i]], y_train.iloc[samples[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       0   1   2   3   4   5   6   7   8   9  ...  90  91  92  93  94  95  96  \\\n",
       "1782   0   0   0   1   1   1   1   1   0   1 ...   1   0   1   1   1   1   1   \n",
       "3917   0   0   0   0   0   0   0   1   0   1 ...   1   0   0   0   1   0   1   \n",
       "221    0   1   1   1   0   1   0   1   0   1 ...   0   0   1   1   1   0   0   \n",
       "2135   0   0   0   0   0   1   0   1   0   0 ...   0   0   0   0   0   0   0   \n",
       "5224   1   0   0   1   0   0   0   0   0   0 ...   0   0   0   0   0   0   1   \n",
       "1168   0   0   1   0   0   1   0   0   0   1 ...   1   0   1   0   1   1   0   \n",
       "879    0   0   1   0   1   0   1   0   0   1 ...   0   0   1   0   0   0   0   \n",
       "156    0   1   0   0   0   0   0   0   0   0 ...   0   0   0   1   1   0   0   \n",
       "1657   1   0   0   1   1   0   1   1   1   1 ...   1   0   1   0   0   0   1   \n",
       "323    1   0   1   0   1   0   0   1   0   0 ...   1   1   1   1   0   0   0   \n",
       "5302   0   1   0   1   0   0   0   1   1   0 ...   0   1   1   1   0   1   0   \n",
       "2611   0   1   0   0   1   0   0   0   1   0 ...   0   1   0   0   1   1   1   \n",
       "811    0   1   0   1   0   0   1   0   0   0 ...   0   0   0   1   1   0   0   \n",
       "393    0   0   0   0   1   1   1   1   1   0 ...   1   1   1   1   1   1   1   \n",
       "3593   0   0   0   0   0   0   0   1   0   0 ...   0   0   1   1   0   1   0   \n",
       "2638   1   1   1   1   0   0   0   1   0   1 ...   1   1   1   0   0   1   1   \n",
       "2187   1   0   1   0   0   0   1   1   1   0 ...   0   0   0   1   1   1   1   \n",
       "5351   0   0   0   1   0   1   0   0   0   0 ...   0   1   1   0   0   1   1   \n",
       "319    0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   1   0   \n",
       "167    0   0   1   1   1   1   1   1   0   1 ...   0   1   1   1   0   0   1   \n",
       "746    1   1   0   1   1   0   0   1   0   1 ...   1   0   1   1   0   1   1   \n",
       "5470   1   0   1   1   1   1   0   1   1   0 ...   1   1   1   1   1   0   1   \n",
       "3707   1   1   1   1   1   1   0   1   1   1 ...   1   1   1   0   1   1   0   \n",
       "2764   1   0   1   1   0   1   1   1   0   1 ...   0   1   1   1   1   1   0   \n",
       "5112   0   1   1   1   0   0   1   0   1   1 ...   0   0   0   0   0   0   1   \n",
       "4006   1   0   1   1   1   1   1   1   0   0 ...   1   0   0   0   1   1   1   \n",
       "1871   0   0   0   1   0   1   0   1   1   1 ...   0   0   0   1   1   1   0   \n",
       "5756   0   1   1   0   1   1   1   1   1   1 ...   1   1   1   1   1   1   0   \n",
       "3193   1   1   1   1   1   0   0   1   1   0 ...   1   0   1   1   0   0   0   \n",
       "3754   0   0   1   1   1   1   1   0   0   0 ...   1   1   1   1   1   1   0   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  .. ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "3628   1   0   0   1   0   0   0   1   0   0 ...   0   1   0   0   0   1   0   \n",
       "4829   0   1   0   0   0   0   0   0   1   1 ...   0   1   1   1   0   1   0   \n",
       "2149   1   0   0   1   0   1   0   1   1   1 ...   1   0   1   1   1   0   1   \n",
       "139    1   1   0   1   1   0   0   0   1   0 ...   1   0   1   1   1   1   0   \n",
       "5829   0   0   1   1   1   1   1   1   1   1 ...   0   1   1   0   0   0   1   \n",
       "5274   1   1   1   1   1   1   1   0   1   0 ...   1   1   1   1   1   1   1   \n",
       "2284   0   1   1   0   0   1   0   0   1   0 ...   0   0   0   0   0   1   1   \n",
       "5010   0   1   0   1   0   0   1   1   0   0 ...   1   1   0   1   1   1   0   \n",
       "1149   1   0   1   1   1   0   1   0   0   1 ...   1   1   1   1   1   1   0   \n",
       "4048   0   1   1   1   0   0   0   1   1   0 ...   0   1   0   1   1   0   1   \n",
       "2498   1   0   0   0   1   1   1   0   0   1 ...   1   0   0   0   1   0   0   \n",
       "2273   1   0   1   0   1   0   1   1   0   0 ...   1   1   1   1   0   1   1   \n",
       "2526   0   0   0   1   1   1   0   1   1   1 ...   0   1   0   1   0   0   1   \n",
       "463    1   0   0   0   1   0   0   0   0   0 ...   0   1   0   0   0   0   0   \n",
       "3307   1   0   0   1   0   0   1   1   0   1 ...   0   1   1   1   0   1   0   \n",
       "3132   1   0   0   1   0   0   0   1   0   1 ...   1   1   1   0   1   1   0   \n",
       "4985   1   1   1   1   1   1   1   0   0   0 ...   0   0   1   0   0   0   0   \n",
       "594    0   1   1   1   0   1   0   1   0   1 ...   1   0   1   1   1   1   1   \n",
       "3080   1   1   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   0   0   \n",
       "1807   0   0   1   0   1   1   0   1   0   1 ...   0   1   1   0   1   1   1   \n",
       "5136   0   0   0   0   1   0   0   0   1   0 ...   0   0   0   1   1   0   0   \n",
       "450    1   1   1   1   1   1   1   1   1   1 ...   1   1   1   1   1   1   1   \n",
       "3043   0   1   1   1   1   0   0   0   1   1 ...   1   0   1   1   0   1   0   \n",
       "5826   1   0   1   0   1   0   1   1   1   0 ...   0   1   0   1   0   1   0   \n",
       "518    0   0   1   0   0   1   1   0   1   0 ...   1   0   1   0   0   1   0   \n",
       "2522   0   1   0   1   0   0   1   0   0   0 ...   1   0   1   1   0   1   1   \n",
       "312    0   1   0   1   0   1   0   1   0   0 ...   1   1   0   1   1   0   0   \n",
       "5887   1   1   1   1   0   1   1   1   1   1 ...   0   1   0   1   0   0   0   \n",
       "4483   1   1   1   1   0   1   1   1   1   0 ...   0   0   1   1   1   1   1   \n",
       "2647   0   0   0   0   0   1   0   0   0   0 ...   0   0   0   0   0   1   0   \n",
       "\n",
       "      97  98  99  \n",
       "1782   1   0   0  \n",
       "3917   0   0   0  \n",
       "221    0   0   0  \n",
       "2135   0   0   0  \n",
       "5224   0   1   1  \n",
       "1168   1   0   0  \n",
       "879    1   0   0  \n",
       "156    0   0   0  \n",
       "1657   0   0   0  \n",
       "323    0   0   1  \n",
       "5302   0   1   0  \n",
       "2611   0   1   1  \n",
       "811    1   0   1  \n",
       "393    1   0   0  \n",
       "3593   1   1   1  \n",
       "2638   0   0   0  \n",
       "2187   1   1   0  \n",
       "5351   0   1   1  \n",
       "319    0   1   0  \n",
       "167    1   1   1  \n",
       "746    1   1   0  \n",
       "5470   0   1   0  \n",
       "3707   0   0   0  \n",
       "2764   1   1   0  \n",
       "5112   0   0   0  \n",
       "4006   1   0   1  \n",
       "1871   1   1   1  \n",
       "5756   1   1   1  \n",
       "3193   1   1   1  \n",
       "3754   0   0   1  \n",
       "...   ..  ..  ..  \n",
       "3628   0   0   0  \n",
       "4829   0   0   0  \n",
       "2149   0   0   1  \n",
       "139    0   0   1  \n",
       "5829   1   1   1  \n",
       "5274   1   1   0  \n",
       "2284   0   0   1  \n",
       "5010   0   1   0  \n",
       "1149   1   1   0  \n",
       "4048   1   1   1  \n",
       "2498   1   0   0  \n",
       "2273   0   1   1  \n",
       "2526   0   1   1  \n",
       "463    0   1   1  \n",
       "3307   1   1   1  \n",
       "3132   1   1   0  \n",
       "4985   1   1   0  \n",
       "594    1   0   1  \n",
       "3080   1   1   0  \n",
       "1807   0   1   1  \n",
       "5136   0   0   0  \n",
       "450    1   1   1  \n",
       "3043   0   1   1  \n",
       "5826   0   0   0  \n",
       "518    1   1   0  \n",
       "2522   1   0   1  \n",
       "312    0   0   0  \n",
       "5887   0   0   1  \n",
       "4483   1   1   0  \n",
       "2647   0   0   1  \n",
       "\n",
       "[1980 rows x 100 columns]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df = pd.DataFrame(index=X_test.index, columns=list(range(n_estimators)))\n",
    "for i in range(n_estimators):\n",
    "    y_pred_df.iloc[:, i] = trees[i].predict(X_test)\n",
    "\n",
    "y_pred_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6571146245059288"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (y_pred_df.sum(axis=1) >= (n_estimators / 2)).astype(np.int)\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.f1_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6494949494949495"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, bootstrap=True,\n",
    "                        random_state=42, n_jobs=-1, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6445783132530121, 0.6424242424242425)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.4\n",
    "\n",
    "Estimate te probability as %models that predict positive\n",
    "\n",
    "Modify the probability threshold and select the one that maximizes the F1-Score #default es 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  percentage\n",
       "1   3000         0.5\n",
       "0   3000         0.5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts().to_frame('count').assign(percentage = lambda x: x/x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1782    58\n",
       "3917    37\n",
       "221     45\n",
       "2135    18\n",
       "5224    32\n",
       "1168    37\n",
       "879     28\n",
       "156     18\n",
       "1657    61\n",
       "323     33\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df.sum(axis=1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5545454545454546\n",
      "0.5398989898989899\n",
      "0.5772727272727273\n",
      "0.5510101010101011\n",
      "0.5661616161616162\n",
      "0.5368686868686868\n",
      "0.548989898989899\n",
      "0.555050505050505\n",
      "0.5484848484848485\n",
      "0.544949494949495\n",
      "0.5595959595959596\n",
      "0.5626262626262626\n",
      "0.554040404040404\n",
      "0.5651515151515152\n",
      "0.5732323232323232\n",
      "0.55\n",
      "0.5661616161616162\n",
      "0.5348484848484848\n",
      "0.5494949494949495\n",
      "0.546969696969697\n",
      "0.5424242424242425\n",
      "0.5595959595959596\n",
      "0.5636363636363636\n",
      "0.5732323232323232\n",
      "0.5434343434343434\n",
      "0.5717171717171717\n",
      "0.55\n",
      "0.5575757575757576\n",
      "0.5555555555555556\n",
      "0.5590909090909091\n",
      "0.5388888888888889\n",
      "0.5454545454545454\n",
      "0.5707070707070707\n",
      "0.5429292929292929\n",
      "0.5494949494949495\n",
      "0.5525252525252525\n",
      "0.5626262626262626\n",
      "0.5378787878787878\n",
      "0.5525252525252525\n",
      "0.5843434343434344\n",
      "0.5641414141414142\n",
      "0.5565656565656566\n",
      "0.5414141414141415\n",
      "0.5545454545454546\n",
      "0.5747474747474748\n",
      "0.555050505050505\n",
      "0.545959595959596\n",
      "0.5474747474747474\n",
      "0.5494949494949495\n",
      "0.5737373737373738\n",
      "0.5666666666666667\n",
      "0.5525252525252525\n",
      "0.5742424242424242\n",
      "0.5555555555555556\n",
      "0.5691919191919191\n",
      "0.5616161616161616\n",
      "0.5686868686868687\n",
      "0.5404040404040404\n",
      "0.5535353535353535\n",
      "0.5585858585858586\n",
      "0.552020202020202\n",
      "0.5712121212121212\n",
      "0.543939393939394\n",
      "0.5691919191919191\n",
      "0.5575757575757576\n",
      "0.5535353535353535\n",
      "0.5707070707070707\n",
      "0.554040404040404\n",
      "0.5696969696969697\n",
      "0.553030303030303\n",
      "0.5565656565656566\n",
      "0.5373737373737374\n",
      "0.555050505050505\n",
      "0.5712121212121212\n",
      "0.5510101010101011\n",
      "0.5595959595959596\n",
      "0.5565656565656566\n",
      "0.555050505050505\n",
      "0.5863636363636363\n",
      "0.5646464646464646\n",
      "0.5868686868686869\n",
      "0.5732323232323232\n",
      "0.5757575757575758\n",
      "0.5484848484848485\n",
      "0.547979797979798\n",
      "0.5676767676767677\n",
      "0.5782828282828283\n",
      "0.5474747474747474\n",
      "0.5585858585858586\n",
      "0.5383838383838384\n",
      "0.5636363636363636\n",
      "0.5419191919191919\n",
      "0.555050505050505\n",
      "0.5474747474747474\n",
      "0.5555555555555556\n",
      "0.5696969696969697\n",
      "0.5601010101010101\n",
      "0.5510101010101011\n",
      "0.5626262626262626\n",
      "0.5601010101010101\n"
     ]
    }
   ],
   "source": [
    "res=[]\n",
    "for i in range(y_pred_df.shape[1]):\n",
    "    print(metrics.accuracy_score(y_pred_df.iloc[:,i], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5458290422245108\n",
      "0.5438157235853781\n",
      "0.5821268097853219\n",
      "0.5539387857501256\n",
      "0.5732737208147044\n",
      "0.5361659079413252\n",
      "0.5464702894870493\n",
      "0.5645081562036579\n",
      "0.5466531440162272\n",
      "0.5460957178841309\n",
      "0.56312625250501\n",
      "0.5661322645290581\n",
      "0.5673689367956884\n",
      "0.5649317837291561\n",
      "0.5777111444277861\n",
      "0.5456399796022438\n",
      "0.5583547557840617\n",
      "0.5350832912670369\n",
      "0.5481256332320162\n",
      "0.5458227848101266\n",
      "0.5419615773508594\n",
      "0.5587044534412956\n",
      "0.5550978372811536\n",
      "0.5818901533894113\n",
      "0.5401831129196338\n",
      "0.5677879714576962\n",
      "0.5423728813559322\n",
      "0.5548780487804877\n",
      "0.5604395604395604\n",
      "0.5676077265973255\n",
      "0.5276771857216761\n",
      "0.5472837022132796\n",
      "0.5728643216080401\n",
      "0.5486284289276808\n",
      "0.5526579739217653\n",
      "0.5447070914696814\n",
      "0.5652610441767068\n",
      "0.5329249617151608\n",
      "0.5488798370672098\n",
      "0.5772984078068824\n",
      "0.5708602685231227\n",
      "0.5565656565656566\n",
      "0.536261491317671\n",
      "0.5585585585585585\n",
      "0.580259222333001\n",
      "0.5557236510337872\n",
      "0.5415604283528812\n",
      "0.5456389452332657\n",
      "0.5476673427991886\n",
      "0.5693877551020409\n",
      "0.5622448979591836\n",
      "0.5547738693467337\n",
      "0.5722983257229833\n",
      "0.5555555555555556\n",
      "0.5787654320987655\n",
      "0.5677290836653386\n",
      "0.5588842975206613\n",
      "0.5390070921985816\n",
      "0.5606361829025845\n",
      "0.5522540983606558\n",
      "0.5508860759493671\n",
      "0.5709954522486105\n",
      "0.5455460493205837\n",
      "0.5641287685232499\n",
      "0.5593561368209257\n",
      "0.5526315789473684\n",
      "0.5783730158730158\n",
      "0.5542655224634022\n",
      "0.5617283950617283\n",
      "0.5319936541512428\n",
      "0.5605605605605606\n",
      "0.5566311713455954\n",
      "0.5539240506329113\n",
      "0.5769805680119582\n",
      "0.5485017775520569\n",
      "0.5578093306288032\n",
      "0.5565656565656566\n",
      "0.5502807554874936\n",
      "0.5907046476761618\n",
      "0.5552115583075337\n",
      "0.5809426229508197\n",
      "0.5734477536597679\n",
      "0.5696721311475409\n",
      "0.5507537688442211\n",
      "0.5567112431896979\n",
      "0.5668016194331984\n",
      "0.5759268664296597\n",
      "0.5419222903885481\n",
      "0.5621242484969939\n",
      "0.5336734693877552\n",
      "0.5718533201189298\n",
      "0.5293201868188895\n",
      "0.5511971472236373\n",
      "0.5488418932527694\n",
      "0.5519348268839104\n",
      "0.5786350148367952\n",
      "0.5681705503222608\n",
      "0.5521410579345087\n",
      "0.5763209393346379\n",
      "0.5589873417721518\n"
     ]
    }
   ],
   "source": [
    "res1=[]\n",
    "for i in range(y_pred_df.shape[1]):\n",
    "    print(metrics.f1_score(y_pred_df.iloc[:,i], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.5\n",
    "\n",
    "Ensemble using weighted voting using the oob_error\n",
    "\n",
    "Evaluate using the following metrics:\n",
    "* Accuracy\n",
    "* F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6445783132530121, 0.6424242424242425)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, bootstrap=True,\n",
    "                        random_state=42, n_jobs=-1, oob_score=True)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.zeros(clf.n_estimators)\n",
    "y_pred_all_ = np.zeros((X_test.shape[0], clf.n_estimators))\n",
    "\n",
    "for i in range(clf.n_estimators):\n",
    "    oob_sample = ~clf.estimators_samples_[i]\n",
    "    y_pred_ = clf.estimators_[i].predict(X_train.values[oob_sample])\n",
    "    errors[i] = metrics.accuracy_score(y_pred_, y_train.values[oob_sample])\n",
    "    y_pred_all_[:, i] = clf.estimators_[i].predict(X_test)\n",
    "    \n",
    "alpha = (1 - errors) / (1 - errors).sum()\n",
    "y_pred = (np.sum(y_pred_all_ * alpha, axis=1) >= 0.5).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6511397423191279, 0.6444444444444445)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.6\n",
    "\n",
    "Estimate te probability of the weighted voting\n",
    "\n",
    "Modify the probability threshold and select the one that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_oob = []\n",
    "for sample in samples:\n",
    "    samples_oob.append(sorted(set(range(n_samples)) - set(sample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.zeros(n_estimators)\n",
    "\n",
    "for i in range(n_estimators):\n",
    "    y_pred_ = trees[i].predict(X_train.iloc[samples_oob[i]])\n",
    "    errors[i] = 1 - metrics.accuracy_score(y_train.iloc[samples_oob[i]], y_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'OOB error of each tree')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.scatter(range(n_estimators), errors)\n",
    "plt.xlim([0, n_estimators])\n",
    "plt.title('OOB error of each tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = (1 - errors) / (1 - errors).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_sum_1 = ((y_pred_df) * alpha).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1782    0.582289\n",
       "3917    0.370041\n",
       "221     0.451645\n",
       "2135    0.181178\n",
       "5224    0.320452\n",
       "1168    0.370798\n",
       "879     0.279333\n",
       "156     0.179389\n",
       "1657    0.609606\n",
       "323     0.331077\n",
       "5302    0.449422\n",
       "2611    0.299635\n",
       "811     0.448833\n",
       "393     0.630987\n",
       "3593    0.460015\n",
       "2638    0.489268\n",
       "2187    0.657659\n",
       "5351    0.479262\n",
       "319     0.109387\n",
       "167     0.670352\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_sum_1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6530408773678963, 0.6484848484848484)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (weighted_sum_1 >= 0.5).astype(np.int)\n",
    "\n",
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.7\n",
    "\n",
    "Estimate a logistic regression using as input the estimated classifiers\n",
    "\n",
    "Modify the probability threshold such that maximizes the F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = pd.DataFrame(index=X_train.index, columns=list(range(n_estimators))) #cada modelo hace overfitin\n",
    "\n",
    "for i in range(n_estimators):\n",
    "    X_train_2[i] = trees[i].predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2',\n",
       "           random_state=None, refit=True, scoring=None, solver='lbfgs',\n",
       "           tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "lr = LogisticRegressionCV(cv = 5 )\n",
    "lr.fit(X_train_2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03202204, 0.03322447, 0.03259434, 0.03336937, 0.03277787,\n",
       "        0.03334688, 0.0327037 , 0.03345375, 0.03323121, 0.03360643,\n",
       "        0.03228301, 0.03347795, 0.03227008, 0.03319649, 0.03247659,\n",
       "        0.03292581, 0.03261363, 0.03309421, 0.03325745, 0.03258211,\n",
       "        0.0327861 , 0.03303638, 0.03452604, 0.03278867, 0.03192832,\n",
       "        0.03286407, 0.03247466, 0.032441  , 0.0326296 , 0.03189279,\n",
       "        0.03366277, 0.03293174, 0.03289413, 0.03344521, 0.03276032,\n",
       "        0.03304766, 0.03269976, 0.03355352, 0.03256685, 0.03225982,\n",
       "        0.03290834, 0.0326421 , 0.03290538, 0.03375285, 0.03286841,\n",
       "        0.0327464 , 0.03240748, 0.03245771, 0.0329707 , 0.03169045,\n",
       "        0.03285974, 0.03339411, 0.0330419 , 0.03234921, 0.03217838,\n",
       "        0.03304465, 0.03289963, 0.03299245, 0.03323476, 0.03317454,\n",
       "        0.03286333, 0.03301111, 0.03214849, 0.0328216 , 0.03282581,\n",
       "        0.03218907, 0.03253907, 0.03382013, 0.03260814, 0.03363583,\n",
       "        0.03270115, 0.03319634, 0.03317548, 0.03262332, 0.03261515,\n",
       "        0.03331021, 0.0310567 , 0.03300686, 0.03384561, 0.03188028,\n",
       "        0.03362494, 0.03271413, 0.03273403, 0.03279575, 0.03232537,\n",
       "        0.03211345, 0.0330148 , 0.03311176, 0.03277878, 0.0324219 ,\n",
       "        0.03281061, 0.03201156, 0.03304483, 0.03329758, 0.03239321,\n",
       "        0.0327856 , 0.0328224 , 0.03343083, 0.03279331, 0.03350437]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(y_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6495983935742972, 0.6474747474747474)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6439317953861585, 0.6414141414141414)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_all_ = np.zeros((X_test.shape[0], clf.n_estimators))\n",
    "X_train_3 = np.zeros((X_train.shape[0], clf.n_estimators))\n",
    "\n",
    "for i in range(clf.n_estimators):\n",
    "\n",
    "    X_train_3[:, i] = clf.estimators_[i].predict(X_train)\n",
    "    y_pred_all_[:, i] = clf.estimators_[i].predict(X_test)\n",
    "    \n",
    "lr = LogisticRegressionCV(cv=5)\n",
    "lr.fit(X_train_3, y_train)\n",
    "\n",
    "y_pred = lr.predict(y_pred_all_)\n",
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5773930753564155, 0.5808080808080808)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
